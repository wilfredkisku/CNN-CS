{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs-net.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vMENiDsk5dI"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from pathlib import Path\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "from sklearn.datasets import load_sample_image\n",
        "from sklearn.feature_extraction import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMGlSEbKlZMm"
      },
      "source": [
        "def create(pp, img, p):\n",
        "\n",
        "    img_ = np.zeros((p, 128, 128, 1), dtype=np.float32)\n",
        "\n",
        "    for i in range(len(img)):\n",
        "        mask = np.random.choice([0, 1], size=(128, 128), p=[1-pp, pp])\n",
        "        idx_w, idx_h = np.where(mask ==  1)\n",
        "\n",
        "        for j in range(len(idx_w)):\n",
        "            img[i, idx_w[j],idx_h[j],0] = 0\n",
        "\n",
        "        img_[i,:,:,0] = img[i,:,:,0]\n",
        "    return img_\n",
        "\n",
        "def curate(path, lt,  x, y):\n",
        "\n",
        "    cnt = 0\n",
        "    for idx, j in tqdm(enumerate(lt)):\n",
        "        onlyfiles   = [f for f in listdir(lt[idx]) if isfile(join(lt[idx], f))]\n",
        "        onlyfiles.remove('Thumbs.db')\n",
        "\n",
        "        for _, i in enumerate(onlyfiles):\n",
        "            p = join(str(lt[idx]),i)\n",
        "            img = cv2.imread(p, 0)\n",
        "            y_patches = image.extract_patches_2d(img, (128,128), max_patches = 8)\n",
        "\n",
        "            y_patches = np.reshape(y_patches,(8, 128,128,-1))\n",
        "\n",
        "\n",
        "            y_patch = copy.deepcopy(y_patches)\n",
        "            x_patches = create(0.85, y_patch, 8)\n",
        "\n",
        "            for k in range(len(x_patches)):\n",
        "                x[cnt] = x_patches[k]\n",
        "                y[cnt] = y_patches[k]\n",
        "                cnt += 1\n",
        "\n",
        "\n",
        "def curate_(path, lt,  x, y):\n",
        "\n",
        "    cnt = 0\n",
        "    for idx, j in tqdm(enumerate(lt)):\n",
        "        onlyfiles   = [f for f in listdir(lt[idx]) if isfile(join(lt[idx], f))]\n",
        "\n",
        "        for _, i in enumerate(onlyfiles):\n",
        "            p = join(str(lt[idx]),i)\n",
        "            img = cv2.imread(p, 0)\n",
        "            y_patches = image.extract_patches_2d(img, (128,128), max_patches = 2)\n",
        "\n",
        "            y_patches = np.reshape(y_patches,(2, 128,128,-1))\n",
        "\n",
        "\n",
        "            y_patch = copy.deepcopy(y_patches)\n",
        "            x_patches = create(0.85, y_patch, 2)\n",
        "\n",
        "            for k in range(len(x_patches)):\n",
        "                x[cnt] = x_patches[k]\n",
        "                y[cnt] = y_patches[k]\n",
        "                cnt += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V6XKSkcmPba"
      },
      "source": [
        "def psnr_mean(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.image.psnr(y_true, y_pred, max_val=1.0))\n",
        "\n",
        "\n",
        "def ssim_loss(true, pred):\n",
        "    return 1 - tf.reduce_mean(tf.image.ssim(true, pred, 1.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cT0U8OUmThR"
      },
      "source": [
        "def SimpleCSNet2():\n",
        "\n",
        "    input_layer = tf.keras.layers.Input((128, 128, 1))\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='orthogonal')(input_layer)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='orthogonal')(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='orthogonal')(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='orthogonal')(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='orthogonal')(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='orthogonal')(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    output_layer = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same', kernel_initializer='orthogonal')(x)\n",
        "\n",
        "    ae = tf.keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n",
        "    ae.compile(optimizer='adam', loss=ssim_loss, metrics=[psnr_mean])\n",
        "\n",
        "    ae.summary()\n",
        "\n",
        "    return ae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPip9T1BnLRk"
      },
      "source": [
        "def SimpleCSNet():\n",
        "\n",
        "    input_layer = tf.keras.layers.Input((128, 128, 1))\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(8, (3,3), padding='same')(input_layer)\n",
        "    conv1 = tf.keras.layers.ReLU()(conv1)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(8, (3,3), padding='same')(conv1)\n",
        "    conv2 = tf.keras.layers.ReLU()(conv2)\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D(16, (3,3), padding='same')(conv2)\n",
        "    conv3 = tf.keras.layers.ReLU()(conv3)\n",
        "\n",
        "    conv4 = tf.keras.layers.Conv2D(16, (3,3), padding='same')(conv3)\n",
        "    conv4 = tf.keras.layers.ReLU()(conv4)\n",
        "\n",
        "    conv5 = tf.keras.layers.Conv2D(32, (3,3), padding='same')(conv4)\n",
        "    conv5 = tf.keras.layers.ReLU()(conv5)\n",
        "\n",
        "    conv6 = tf.keras.layers.Conv2D(32, (3,3), padding='same')(conv5)\n",
        "    conv6 = tf.keras.layers.ReLU()(conv6)\n",
        "\n",
        "    output_layer = tf.keras.layers.Conv2D(1, (1,1), padding='same', activation='sigmoid')(conv6)\n",
        "\n",
        "    ae = tf.keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n",
        "    ae.compile(optimizer='adam', loss=ssim_loss, metrics = [psnr_mean])\n",
        "\n",
        "    ae.summary()\n",
        "\n",
        "    return ae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1saRBTMmW1R"
      },
      "source": [
        "def fire(x, squeeze, expand):\n",
        "    y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n",
        "    y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation='relu', padding='same')(y)\n",
        "    y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=3, activation='relu', padding='same')(y)\n",
        "    return tf.keras.layers.concatenate([y1, y3])\n",
        "\n",
        "def fire_module(squeeze, expand):\n",
        "    return lambda x: fire(x, squeeze, expand)\n",
        "\n",
        "def SimpleCSNet_sq():\n",
        "    input_layer = tf.keras.layers.Input(shape=[128, 128, 1])\n",
        "    y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(input_layer)\n",
        "    y = fire_module(32, 32)(y)\n",
        "    y = fire_module(32, 32)(y)\n",
        "    y = fire_module(32, 32)(y)\n",
        "    y = fire_module(32, 32)(y)\n",
        "    y = fire_module(32, 32)(y)\n",
        "    output_layer = tf.keras.layers.Conv2D(1, (1,1), padding = 'same', activation='sigmoid')(y)\n",
        "\n",
        "    ae = tf.keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n",
        "    ae.compile(optimizer='adam', loss=ssim_loss, metrics = [psnr_mean])\n",
        "    ae.summary()\n",
        "\n",
        "    return ae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl_zkb3zmpiF"
      },
      "source": [
        "count_n = 0\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "\n",
        "Path1 = Path('/workspace/storage/cnn-cs/data/images')\n",
        "Path2 = Path('/workspace/storage/cnn-cs/data/train')\n",
        "\n",
        "lst  = [x for x in Path1.iterdir() if Path1.is_dir()]\n",
        "lst_ = [x for x in Path2.iterdir() if Path2.is_dir()]\n",
        "\n",
        "for i in range(len(lst)):\n",
        "    count_n += len(os.listdir(os.path.join(Path1,lst[i]))) - 1\n",
        "\n",
        "x_train = np.zeros((count_n * 8, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "y_train = np.zeros((count_n * 8, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "\n",
        "curate(Path1, lst, x_train, y_train)\n",
        "\n",
        "x_train = x_train / 255.\n",
        "y_train = y_train / 255.\n",
        "\n",
        "count_n = 0\n",
        "\n",
        "for i in range(len(lst_)):\n",
        "    count_n += len(os.listdir(os.path.join(Path2,lst_[i])))\n",
        "\n",
        "X_train = np.zeros((count_n * 2, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "Y_train = np.zeros((count_n * 2, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "\n",
        "curate_(Path2, lst_, X_train, Y_train)\n",
        "\n",
        "X_train = X_train / 255.\n",
        "Y_train = Y_train / 255.\n",
        "\n",
        "X_TRAIN, X_VAL, Y_TRAIN, Y_VAL = train_test_split(np.concatenate((x_train,X_train),axis=0), np.concatenate((y_train,Y_train),axis=0), test_size = 0.2, random_state = 42)\n",
        "\n",
        "model_cnn = SimpleCSNet2()\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('/workspace/data/cs-simple-model-1000.h5', verbose=1, save_best_only=True)\n",
        "history = model_cnn.fit(X_TRAIN, Y_TRAIN, epochs=500, batch_size=64, shuffle=True, validation_data=(X_VAL, Y_VAL), verbose = 1,  callbacks=[checkpointer])\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df.to_csv('/workspace/data/cs-simple-history-1000.csv')\n",
        "\n",
        "print('End of training ...')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}